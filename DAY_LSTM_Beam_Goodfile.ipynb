{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8tQJd2YSCfWR"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D7tqLMoKF6uq"
   },
   "source": [
    "# LSTM Model with Beam Search\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "MvEblsgEXxrd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found and verified text8.zip\n",
      "Data size 100000000\n",
      "training data size: 99999000 ons anarchists advocate social relations based upon voluntary as\n",
      "validation data size: 1000  anarchism originated as a term of abuse first used against earl\n"
     ]
    }
   ],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "from six.moves import range\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "\n",
    "url = 'http://mattmahoney.net/dc/'\n",
    "\n",
    "def maybe_download(filename, expected_bytes):\n",
    "    \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
    "    if not os.path.exists(filename):\n",
    "        filename, _ = urlretrieve(url + filename, filename)\n",
    "    statinfo = os.stat(filename)\n",
    "    if statinfo.st_size == expected_bytes:\n",
    "        print('Found and verified %s' % filename)\n",
    "    else:\n",
    "        print(statinfo.st_size)\n",
    "        raise Exception(\n",
    "          'Failed to verify ' + filename + '. Can you get to it with a browser?')\n",
    "    return filename\n",
    "\n",
    "filename = maybe_download('text8.zip', 31344016)\n",
    "\n",
    "def read_data(filename):\n",
    "    f = zipfile.ZipFile(filename)\n",
    "    for name in f.namelist():\n",
    "        return tf.compat.as_str(f.read(name))\n",
    "    f.close()\n",
    "\n",
    "text = read_data(filename)\n",
    "print('Data size %d' % len(text))\n",
    "\n",
    "# Create small validation set\n",
    "\n",
    "valid_size = 1000\n",
    "valid_text = text[:valid_size]\n",
    "train_text = text[valid_size:]\n",
    "train_size = len(train_text)\n",
    "print('training data size: %s %s' % (train_size, train_text[:64]))\n",
    "print('validation data size: %s %s' % (valid_size, valid_text[:64]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 0,  6, 12,  5], dtype=int32), array([1, 7, 0, 6], dtype=int32), array([2, 8, 1, 7], dtype=int32)]\n",
      "[array([2, 8, 1, 7], dtype=int32), array([3, 9, 2, 8], dtype=int32), array([ 4, 10,  3,  9], dtype=int32)]\n",
      "[array([ 4, 10,  3,  9], dtype=int32), array([ 5, 11,  4, 10], dtype=int32), array([ 6, 12,  5, 11], dtype=int32)]\n",
      "[array([ 6, 12,  5, 11], dtype=int32), array([7, 0, 6, 0], dtype=int32), array([8, 1, 7, 1], dtype=int32)]\n",
      "[['ab', 'mn', 'yz', 'kl'], ['cd', 'op', 'ab', 'mn'], ['ef', 'qr', 'cd', 'op']]\n",
      "[['ef', 'qr', 'cd', 'op'], ['gh', 'st', 'ef', 'qr'], ['ij', 'uv', 'gh', 'st']]\n",
      "[['ij', 'uv', 'gh', 'st'], ['kl', 'wx', 'ij', 'uv'], ['mn', 'yz', 'kl', 'wx']]\n",
      "[['mn', 'yz', 'kl', 'wx'], ['op', 'ab', 'mn', 'ab'], ['qr', 'cd', 'op', 'cd']]\n"
     ]
    }
   ],
   "source": [
    "# DAY\n",
    "#\n",
    "# This is important to understand.  Our NN needs a constant sized vector with each input.  We are\n",
    "# providing that here.  As the video says, just as convolution lets us use the same weight parameters\n",
    "# at different parts of the image, a recurrent neural net lets us use the same weights at different\n",
    "# points in time (or rather, different points in the input sequence).\n",
    "#\n",
    "# The notion of \"unrollings\" is that a recurrent NN has it's output connected to it's input, but really\n",
    "# the way to think about it is over time where the output of time t-1 is input to time t.  That way\n",
    "# of looking at it is like \"unrolling\" the recurrent NN over time so it is understood more as a\n",
    "# sequence of copies of the NN.  \n",
    "# In this case, we are going to be feeding in sequences that are 10 long, so we will in effect\n",
    "# create 10 LSTM cells (which are really just a NN) and hook the output of LSTM cell t with inputs\n",
    "# from input_sub_t and also the output of LSTM cell t-1.\n",
    "\n",
    "# I'm re-writing the BatchGenerator to be more general purpose.  I want it to always output\n",
    "# IDs (not embeddings, not the actual text, but the ID of the embeddings)\n",
    "\n",
    "class SequenceGenerator(object):\n",
    "    '''This class will take a text input and generate batches of IDs suitable for use with\n",
    "    tf.nn.embedding_lookup() (i.e. goes from 0 to len(vocab)-1).  This class can be \n",
    "    inherited to create classes that create IDs for single characters, bigrams, \n",
    "    or entire words.  It also has the ability to take\n",
    "    ID output from the RNN and convert it back to the original text.'''\n",
    "    def __init__(self, text, batch_size, num_unrollings):\n",
    "        self._text = text\n",
    "        self._batch_size = batch_size\n",
    "        self._num_unrollings = num_unrollings\n",
    "        self._init_vocab()\n",
    "        self._init_token_sequence()\n",
    "        self._text = None # garbage collect now that self._token_seq is written\n",
    "        segment = self._token_seq_size // batch_size\n",
    "        self._cursor = [ offset * segment for offset in range(batch_size)]\n",
    "        self._last_batch = self._next_batch()\n",
    "        \n",
    "    def _init_vocab(self):\n",
    "        '''Must be implemented in subclasses and create the following:\n",
    "                self._vocab_dict (text keys and ID values)  \n",
    "                self._reverse_vocab_dict (ID keys and text values)\n",
    "                self.vocab_size'''\n",
    "        raise NotImplementedError\n",
    "    def _init_token_sequence(self):\n",
    "        '''Must be implemented in subclasses and create the following:\n",
    "                self._token_seq = list of token id's in original input order (so duplicate is ok)\n",
    "                self._token_seq_size = the total # of tokens in the input stream\n",
    "                '''\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def token_2_id(self, token):\n",
    "        return self._vocab_dict[token]\n",
    "    def id_2_token(self, token_id):\n",
    "        return self._reverse_vocab_dict[token_id]\n",
    "    def onehot_2_id(self, one_hot):\n",
    "        \"\"\"Turn a 1-hot encoding or a probability distribution over the possible\n",
    "        characters back into its (most likely) ID representation.\n",
    "        This will always return the same result for identical inputs -- it does\n",
    "        not sample across the probability distribution.\n",
    "        This used to be character()\"\"\"\n",
    "        return [c for c in np.argmax(one_hot, 1)]\n",
    "    def id_2_onehot(self, id_list):\n",
    "        '''Turn a list of ids into a list of one_hot encoded vectors'''\n",
    "        identity = tf.constant(np.identity(self.vocab_size, dtype = np.float32))\n",
    "        return tf.nn.embedding_lookup(identity, id_list)\n",
    "    \n",
    "    def softmax_2_sampled_id(self, softmax_distribution):\n",
    "        \"\"\"Turn a softMax probability distribution over the possible\n",
    "        characters into an ID representation based on a sampling over that probability\n",
    "        distribution.\n",
    "        This randomly samples the distribution. So, for example, if in the\n",
    "        softmax distribution 'a' is 40% likely, 'b' is 40% likely and \n",
    "        'c' is 20% likely, this will generate an 'a' 40% of the time\n",
    "        it is called and a 'c' 20% of the time it is called, etc.\"\"\"\n",
    "        r = random.uniform(0, 1)\n",
    "        s = 0\n",
    "        for i in range(len(softmax_distribution)):\n",
    "            s += softmax_distribution[i]\n",
    "            if s >= r:\n",
    "                return i\n",
    "        return len(softmax_distribution) - 1\n",
    "    \n",
    "    def _next_batch(self):\n",
    "        \"\"\"Generate a single row (or unrolling) of length 'batch' from the current \n",
    "        cursor position in the token data.  It will be in the form of a row of token IDs.\"\"\"\n",
    "        batch = np.zeros(shape=(self._batch_size, ), dtype=np.int32)\n",
    "        for b in range(self._batch_size):\n",
    "            batch[b] = self._token_seq[self._cursor[b]]\n",
    "            self._cursor[b] = (self._cursor[b] + 1) % self._token_seq_size\n",
    "        return batch\n",
    "  \n",
    "    def next(self):\n",
    "        \"\"\"Generate the next array of batches from the data. The array consists of\n",
    "        the last batch of the previous array, followed by num_unrollings new ones.\n",
    "        (for a total of num_unrollings + 1).\n",
    "        The reason the last batch from the previous array is included is because\n",
    "        in the previous array, the last batch was just used as a label to the model,\n",
    "        not as an input -- so we include it this next time to be used as an input.\n",
    "        Note that the sequential tokens end up being read into the columns of these\n",
    "        'num_unrolling\" batches.  Each column is a separate part of the token input.\n",
    "        \"\"\"\n",
    "        batches = [self._last_batch]\n",
    "        for step in range(self._num_unrollings):\n",
    "            batches.append(self._next_batch())\n",
    "        self._last_batch = batches[-1]\n",
    "        return batches\n",
    "    \n",
    "    def batches_2_tokens(self, batches):\n",
    "        \"\"\"Convert a sequence of batches back into their (most likely) string\n",
    "        representation.\"\"\"\n",
    "        # DAY\n",
    "        # This mangles the real batch structure in the interest of readability, but\n",
    "        # by doing so, makes your understanding of batches wrong.\n",
    "        # See 'honest_batches2string' below which gives you a better\n",
    "        # understanding of the batch format.\n",
    "\n",
    "        # batches has dimensions (num_unrollings, batch_size)\n",
    "        s = [''] * batches[0].shape[0]  # batches[0].shape[0] will end up being same as batch_size\n",
    "        for b in batches: # there will be num_unrollings of these...\n",
    "            s = [''.join(self.id_2_token(x)) for x in zip(s, b)]  # DAY __ NEEDS WORK\n",
    "        return s\n",
    "\n",
    "    def honest_batches_2_tokens(self, batches):\n",
    "        import pprint\n",
    "        output = []\n",
    "        for b_index, b in enumerate(batches):  # there will be 'num_unrollings' of these\n",
    "            output.append(list())\n",
    "            for token_id_index, token_id in enumerate(b):  # there will be 'batch_size' of these\n",
    "                output[b_index].append(self.id_2_token(token_id))\n",
    "        return pprint.pformat(output)\n",
    "\n",
    "class SingleCharacterGenerator(SequenceGenerator):\n",
    "    def _init_vocab(self):\n",
    "        '''Must be implemented in subclasses and create the following:\n",
    "                self._reverse_vocab_dict (ID keys and text values)\n",
    "                self.vocab_size'''\n",
    "        self.vocab_size = len(string.ascii_lowercase) + 1 # [a-z] + ' '\n",
    "        self._vocab_dict = dict()\n",
    "        self._vocab_dict[' '] = 0\n",
    "        for i, v in enumerate(list(string.ascii_lowercase[:self.vocab_size - 1])):\n",
    "            self._vocab_dict[v] = i+1\n",
    "        self._reverse_vocab_dict = dict(zip(self._vocab_dict.values(), self._vocab_dict.keys()))\n",
    "    def _init_token_sequence(self):\n",
    "        '''Must be implemented in subclasses and create the following:\n",
    "                self._token_seq = list of token id's in original input order (so duplicate is ok)\n",
    "                self._token_seq_size = the total # of tokens in the input stream\n",
    "                '''\n",
    "        first_letter = ord(string.ascii_lowercase[0])\n",
    "        self._token_seq = list()\n",
    "        for char in self._text.lower():\n",
    "            if char in string.ascii_lowercase:\n",
    "                self._token_seq.append(self.token_2_id(char))\n",
    "            elif char == ' ':\n",
    "                self._token_seq.append(self.token_2_id(' '))\n",
    "            else:\n",
    "                pass # don't enter unknown characters (DAY should we have an UNK ID?)\n",
    "        self._token_seq_size = len(self._token_seq)\n",
    "\n",
    "class BigramGenerator(SequenceGenerator):\n",
    "    def _init_vocab(self):\n",
    "        '''Must be implemented in subclasses and create the following:\n",
    "                self._vocab_dict (text keys and ID values)  \n",
    "                self._reverse_vocab_dict (ID keys and text values)\n",
    "                self.vocab_size'''\n",
    "        self._vocab_dict = dict()\n",
    "        self._token_seq = list()\n",
    "        id_index = 0\n",
    "        for i in range(0, len(self._text)-2, 2):\n",
    "            bigram = self._text[i].lower() + self._text[i+1].lower()\n",
    "            if bigram not in self._vocab_dict:\n",
    "                self._vocab_dict[bigram] = id_index\n",
    "                id_index += 1\n",
    "            self._token_seq.append(self.token_2_id(bigram)) # dup ok -- this is just input stream as token ids\n",
    "        self.vocab_size = len(self._vocab_dict)\n",
    "        self._reverse_vocab_dict = dict(zip(self._vocab_dict.values(), self._vocab_dict.keys()))\n",
    "        self._token_seq_size = len(self._token_seq)\n",
    "    def _init_token_sequence(self):\n",
    "        '''Must be implemented in subclasses and create the following:\n",
    "                self._token_seq = list of token id's in original input order (so duplicate is ok)\n",
    "                self._token_seq_size = the total # of tokens in the input stream\n",
    "                '''\n",
    "        pass # I did this work in _init_vocab() to use just one loop\n",
    "\n",
    "\n",
    "if True:\n",
    "    my_text = \"abcdefghijklmnopqrstuvwxyzabcdefghijklmnopqrstuvwxyz\"\n",
    "    #my_batches = SingleCharacterGenerator(my_text.lower(), 4, 2)\n",
    "    my_batches = BigramGenerator(my_text.lower(), 4, 2)\n",
    "    print(my_batches.next())\n",
    "    print(my_batches.next())\n",
    "    print(my_batches.next())\n",
    "    print(my_batches.next())\n",
    "    #my_batches = SingleCharacterGenerator(my_text.lower(), 4, 2)\n",
    "    my_batches = BigramGenerator(my_text.lower(), 4, 2)\n",
    "    print(my_batches.honest_batches_2_tokens(my_batches.next()))\n",
    "    print(my_batches.honest_batches_2_tokens(my_batches.next()))\n",
    "    print(my_batches.honest_batches_2_tokens(my_batches.next()))\n",
    "    print(my_batches.honest_batches_2_tokens(my_batches.next()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "KyVd8FxT5QBc"
   },
   "outputs": [],
   "source": [
    "def logprob(predictions, labels):\n",
    "    \"\"\"Log-probability of the true labels in a predicted batch.\"\"\"\n",
    "    predictions[predictions < 1e-10] = 1e-10\n",
    "    return np.sum(np.multiply(labels, -np.log(predictions))) / labels.shape[0]\n",
    "\n",
    "def sample_distribution(distribution):\n",
    "    \"\"\"Sample one element from a distribution assumed to be an array of normalized\n",
    "    probabilities.\n",
    "    \"\"\"\n",
    "    r = random.uniform(0, 1)\n",
    "    s = 0\n",
    "    for i in range(len(distribution)):\n",
    "        s += distribution[i]\n",
    "        if s >= r:\n",
    "            return i\n",
    "    return len(distribution) - 1\n",
    "\n",
    "def sample(prediction, vocabulary_size):\n",
    "    \"\"\"Turn a (column) prediction into 1-hot encoded samples.\"\"\"\n",
    "    p = np.zeros(shape=[1, vocabulary_size], dtype=np.float)\n",
    "    p[0, sample_distribution(prediction[0])] = 1.0  # prediction is in column format, so it must be indexed by [0]\n",
    "    return p\n",
    "\n",
    "def random_distribution(vocabulary_size):\n",
    "    \"\"\"Generate a random column of probabilities.\"\"\"\n",
    "    b = np.random.uniform(0.0, 1.0, size=[1, vocabulary_size])\n",
    "    return b/np.sum(b, 1)[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "num_unrollings=10\n",
    "num_nodes = 64\n",
    "embedding_size = 10\n",
    "\n",
    "if False:\n",
    "    train_batches = SingleCharacterGenerator(train_text, batch_size, num_unrollings)\n",
    "    vocabulary_size = train_batches.vocab_size\n",
    "    valid_batches = SingleCharacterGenerator(valid_text, 1, 1)\n",
    "else:\n",
    "    train_batches = BigramGenerator(train_text, batch_size, num_unrollings)\n",
    "    vocabulary_size = train_batches.vocab_size\n",
    "    valid_batches = BigramGenerator(valid_text, 1, 1)\n",
    "\n",
    "# Save memory\n",
    "del text\n",
    "del valid_text\n",
    "del train_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beam Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import functools, operator, collections\n",
    "\n",
    "def beam_search(beam, expand_frontier, is_goal, top_k, beam_size):\n",
    "    '''Implement general beam search (forward-pruning mem-efficient search)\n",
    "       Inputs:\n",
    "            beam = list of (path, cost) tuples\n",
    "            expand_frontier =   executable which takes a path (i.e. [id, id2, id3]) and <path_cost> and returns all \n",
    "                                nodes one step forward from path and their associated costs\n",
    "                                in a list of (newpath, cost) tuples\n",
    "            is_goal = executable which takes <path> and <path_cost> and returns True if it\n",
    "                                is the goal\n",
    "            top_k = executable which takes list of (path, cost) tuples and <k> and returns the\n",
    "                                top k elements of the list (using domain specific criteria)\n",
    "            beam_size = the number of paths to keep at any given time\n",
    "        Output:\n",
    "            Chosen path and cost             \n",
    "            '''\n",
    "    print('beam_search debug: entering - beam=%s' % beam)\n",
    "    next_gen = []\n",
    "    done = False\n",
    "    for path, cost in beam:\n",
    "        if isinstance(path, collections.Iterable):\n",
    "            new_paths = expand_frontier(path, cost)\n",
    "        else:\n",
    "            new_paths = expand_frontier([path], cost)\n",
    "        #print('beam_search debug: new_paths=%s' % new_paths)\n",
    "        for entry in new_paths:\n",
    "            if is_goal(*entry):\n",
    "                done = True\n",
    "        #is_done = [is_goal(p, c) for entry in new_paths for p, c in entry]\n",
    "        #print('beam_search debug: is_done=%s' % is_done)\n",
    "        #if any(is_done):\n",
    "        #    done = True\n",
    "        #else:\n",
    "        #    next_gen.extend(new_paths)\n",
    "        next_gen.extend(new_paths)\n",
    "    if done:\n",
    "        print('beam_search debug: DONE, exiting')\n",
    "        return top_k(next_gen, 1)\n",
    "    else:\n",
    "        after_pruning = top_k(next_gen, beam_size)\n",
    "        #print('beam_search debug: after_pruning=%s' % after_pruning)\n",
    "        beam_search(after_pruning, expand_frontier, is_goal, top_k, beam_size)\n",
    "    \n",
    "def is_X_long(path, cost, end_length=1):\n",
    "    #print('is_x_long debug: path=%s, cost=%s, end_length=%s' % (path, cost, end_length))\n",
    "    return True if len(path) >= end_length else False\n",
    "is_80_long = functools.partial(is_X_long, end_length=80)\n",
    "\n",
    "def top_k_min(paths, k):\n",
    "    return sorted(paths, key=operator.itemgetter(1), reverse=False)[:k]\n",
    "def top_k_max(paths, k):\n",
    "    return sorted(paths, key=operator.itemgetter(1), reverse=True)[:k]\n",
    "def k_samples(paths, k):\n",
    "    \"\"\"Sample k elements from a distribution of probabilities.\n",
    "    An entry with high probability has higher chance of being sampled.\n",
    "    \"\"\"\n",
    "    def sample(paths):\n",
    "        path_only, costs = zip(*paths) # this idiom unzips\n",
    "        costs_sum = functools.reduce(sum, costs)\n",
    "        normalized_costs = [costs[i]/costs_sum for i in range(len(costs))]\n",
    "        r = random.uniform(0, 1)\n",
    "        s = 0\n",
    "        for i in range(len(normalized_costs)):\n",
    "            s += normalized_costs[i]\n",
    "            if s >= r:\n",
    "                return paths(i)\n",
    "        return paths(len(normalized_costs) - 1)\n",
    "    result = list()\n",
    "    for i in range(k):\n",
    "        result.append(sample(paths))\n",
    "    return result\n",
    "\n",
    "if False:\n",
    "    def expand_frontier_lstm(path, probability):\n",
    "        with tf.Session(graph=graph) as session:\n",
    "            feed = [path]\n",
    "            reset_sample_state.run()\n",
    "            prediction = sample_prediction.eval({sample_input: feed, keep_prob: 1})\n",
    "            result = list()\n",
    "            for i in range(len(prediction)):\n",
    "                # the path is a list of IDs which is just the index into the \n",
    "                # prediction vector that we got back.  So append this index (ID)\n",
    "                # onto the path and calculate the probability of this new path\n",
    "                # as previous_probability*prediction_for_this_new_node.\n",
    "                result.append( (feed.append(i), probability*prediction[i]) )\n",
    "            return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "Q5rxZK6RDuGe"
   },
   "outputs": [],
   "source": [
    "num_steps = 101\n",
    "# See interesting implementation of 2-layer LSTM (with embeddings) here: http://pastebin.com/YP3sWkG9\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    \n",
    "    # My embedding here will simply be a 2D tensor -- the first\n",
    "    # dimension will hold the ID a (character or bigram) (the index)\n",
    "    # the second dimension will hold the embedding vector.\n",
    "    vocabulary_embeddings = tf.Variable(\n",
    "        tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n",
    "  \n",
    "    # Parameters:\n",
    "    with tf.name_scope('LSTM_cell') as lstm_cell_scope:\n",
    "        with tf.name_scope('input_gate') as input_gate_scope:\n",
    "            # Input gate: input, previous output, and bias.\n",
    "            ix = tf.Variable(tf.truncated_normal([embedding_size, num_nodes], -0.1, 0.1)) # [50, 64]\n",
    "            im = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], -0.1, 0.1))       # [64, 64]\n",
    "            ib = tf.Variable(tf.zeros([1, num_nodes]))                                     # [1, 64]\n",
    "        with tf.name_scope('forget_gate') as forget_gate_scope:\n",
    "            # Forget gate: input, previous output, and bias.\n",
    "            fx = tf.Variable(tf.truncated_normal([embedding_size, num_nodes], -0.1, 0.1))\n",
    "            fm = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], -0.1, 0.1))\n",
    "            fb = tf.Variable(tf.zeros([1, num_nodes]))\n",
    "        with tf.name_scope('memory_cell') as memory_cell_scope:\n",
    "            # Memory cell: input, state and bias.                             \n",
    "            cx = tf.Variable(tf.truncated_normal([embedding_size, num_nodes], -0.1, 0.1))\n",
    "            cm = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], -0.1, 0.1))\n",
    "            cb = tf.Variable(tf.zeros([1, num_nodes]))\n",
    "        with tf.name_scope('output_gate') as output_gate_scope:\n",
    "            # Output gate: input, previous output, and bias.\n",
    "            ox = tf.Variable(tf.truncated_normal([embedding_size, num_nodes], -0.1, 0.1))\n",
    "            om = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], -0.1, 0.1))\n",
    "            ob = tf.Variable(tf.zeros([1, num_nodes]))\n",
    "            \n",
    "            \n",
    "        # Reduce the input/output matmuls from 4 to 1 each by concatenating the 4 gates\n",
    "        concatx = tf.concat(1, [ix, fx, cx, ox])\n",
    "        concatm = tf.concat(1, [im, fm, cm, om])\n",
    "        concatb = tf.concat(1, [ib, fb, cb, ob])\n",
    "        \n",
    "        \n",
    "        # Variables saving state across unrollings.\n",
    "        saved_output = tf.Variable(tf.zeros([batch_size, num_nodes]), trainable=False)\n",
    "        saved_state = tf.Variable(tf.zeros([batch_size, num_nodes]), trainable=False)\n",
    "        # Classifier weights and biases.\n",
    "        w = tf.Variable(tf.truncated_normal([num_nodes, vocabulary_size], -0.1, 0.1)) #output is one-hot vector\n",
    "        b = tf.Variable(tf.zeros([vocabulary_size]))\n",
    "        # Dropout percent\n",
    "        keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "\n",
    "  \n",
    "    # Definition of the cell computation.\n",
    "    def lstm_cell(i, o, state):\n",
    "        \"\"\"Create a LSTM cell. See e.g.: http://arxiv.org/pdf/1402.1128v1.pdf\n",
    "        Note that in this formulation, we omit the various connections between the\n",
    "        previous state and the gates.\"\"\"\n",
    "        with tf.name_scope(lstm_cell_scope):\n",
    "            # #Instead of these 4 matmuls, do the one concatenated matmul and then split results\n",
    "            #input_gate = tf.sigmoid(tf.matmul(i, ix) + tf.matmul(o, im) + ib)\n",
    "            #forget_gate = tf.sigmoid(tf.matmul(i, fx) + tf.matmul(o, fm) + fb)\n",
    "            #update = tf.matmul(i, cx) + tf.matmul(o, cm) + cb\n",
    "            #output_gate = tf.sigmoid(tf.matmul(i, ox) + tf.matmul(o, om) + ob)\n",
    "\n",
    "            concatmatmul = tf.matmul(i, concatx) + tf.matmul(o, concatm) + concatb\n",
    "            input_gate, forget_gate, update, output_gate = tf.split(1, 4, concatmatmul)\n",
    "            input_gate = tf.sigmoid(tf.nn.dropout(input_gate, keep_prob))\n",
    "            forget_gate = tf.sigmoid(forget_gate)\n",
    "            output_gate = tf.sigmoid(tf.nn.dropout(output_gate, keep_prob))\n",
    "            state = forget_gate * state + input_gate * tf.tanh(update)\n",
    "        return output_gate * tf.tanh(state), state\n",
    "    \n",
    "    # The LSTM\n",
    "    #\n",
    "    # In the code above, batch_size (bs) and num_nodes (nn) are both 64 (they don't have to be equal)\n",
    "    # 27 is the vocabulary size, 50 is the embed_size\n",
    "    #\n",
    "    # input_gate(bs, nn)   = sigmoid( input(bs, 50) * ix(50, nn) + output(bs, nn) * im(nn, nn) + ib(1, nn) )\n",
    "    # forget_gate(bs, nn)  = sigmoid( input(bs, 50) * ix(50, nn) + output(bs, nn) * im(nn, nn) + ib(1, nn) )\n",
    "    # output_gate(bs, nn)  = sigmoid( input(bs, 50) * ix(50, nn) + output(bs, nn) * im(nn, nn) + ib(1, nn) )\n",
    "    # update(bs, nn)       = tanh(    input(bs, 50) * cx(50, nn) + output(bs, nn) * cm(nn, nn) + cb(1, nn) )\n",
    "    #\n",
    "    # output(bs, nn) = output_gate(bs, nn) * tanh( state(bs, nn) )\n",
    "    # state(bs, nn)  = forget_gate(bs, nn) * state(bs, nn)  +  input_gate(bs, nn) * update(bs, nn)\n",
    "\n",
    "    # Input data.\n",
    "    train_data = list()\n",
    "    for _ in range(num_unrollings + 1):\n",
    "        train_data.append(\n",
    "            # These 11 elements of train_data will be pulled in from feed_dict\n",
    "            # Note that usually we have seen feed_dict specified as {var_name: value}\n",
    "            # but in this case, since these 11 array elements don't have a var_name, the \n",
    "            # feed_dict will use the tensorflow object as the key instead, i.e.\n",
    "            # feed_dict={<tf.Tensor 'Placeholder_1:0' shape=(64, 27) dtype=float32>: value}\n",
    "            # See below where the feed_dict is prepared before calling session.run.\n",
    "            \n",
    "            # Note that the new shape=[batch_size, ] matches a batch of IDs (the IDs don't have a dimension, they\n",
    "            #    are just integers)\n",
    "            tf.placeholder(tf.int32, shape=[batch_size, ])) #this will be pulled in from feed_dict\n",
    "    # train_data now has the shape (11, 64, 50), or (num_unrollings, batch_size, embedding_size)\n",
    "    # and sequential text from the original text input is 'striped' across the first dimension (11)\n",
    "    \n",
    "    # Create the train_inputs by converting the train_data (batches of IDs) into \n",
    "    #    embeddings (batches of embeddings)\n",
    "    #    Here is what the ID batches look like (num_unrollings=2 (+1), batch_size=4)\n",
    "    #    [array([  1.,   7.,  13.,  19.]), \n",
    "    #     array([  2.,   8.,  14.,  20.]), \n",
    "    #     array([  3.,   9.,  15.,  21.])]\n",
    "    train_inputs = [tf.nn.embedding_lookup(vocabulary_embeddings, id_array) \n",
    "                            for id_array in train_data[:num_unrollings]]\n",
    "    # Create the train_labels by shifting by one time step and then\n",
    "    #    converting the train_data (batches of IDs) into\n",
    "    #    one_hot vectors (batches of one_hots)\n",
    "    train_labels = [train_batches.id_2_onehot(id_array) \n",
    "                            for id_array in train_data[1:]]\n",
    "    \n",
    "    \n",
    "    # Unrolled LSTM loop.\n",
    "    with tf.name_scope(lstm_cell_scope):\n",
    "        outputs = list()\n",
    "        output = saved_output\n",
    "        state = saved_state\n",
    "        for i in train_inputs: # since train_inputs is num_unrollings=10 long, this will create 10 LSTM cells\n",
    "            output, state = lstm_cell(i, output, state)\n",
    "            outputs.append(output)  # at each iter of the lstm_cell, append the character it predicted to outputs.\n",
    "\n",
    "    # State saving across unrollings.\n",
    "    with tf.control_dependencies([saved_output.assign(output),\n",
    "                                saved_state.assign(state)]):\n",
    "        # Classifier.\n",
    "        logits = tf.nn.xw_plus_b(tf.concat(0, outputs), w, b)\n",
    "        loss = tf.reduce_mean(\n",
    "          tf.nn.softmax_cross_entropy_with_logits(\n",
    "            logits, tf.concat(0, train_labels)))\n",
    "        tf.scalar_summary('loss', loss)\n",
    "\n",
    "    # Optimizer.\n",
    "    #   Note that all 10 unrollings are done before the optimizer comes in and looks at the\n",
    "    #   output sequence of 10 chars vs. the label sequence of 10 chars and then calculates\n",
    "    #   the gradients and adjusts the parameters.  Then in the next step another 10 characters\n",
    "    #   will be predicted.\n",
    "    with tf.name_scope(\"Optimizer\"):\n",
    "        global_step = tf.Variable(0)\n",
    "        #learning_rate = tf.train.exponential_decay(\n",
    "        #    10.0, global_step, 5000, 0.1, staircase=True)\n",
    "        learning_rate = tf.train.exponential_decay(\n",
    "            10.0, global_step, num_steps//10, 0.96, staircase=True)\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "        # DAY: this clipping below is the hack to prevent exploding gradients \n",
    "        #(LSTM was the elegant solution to prevent vanishing gradient)\n",
    "        gradients, v = zip(*optimizer.compute_gradients(loss))\n",
    "        gradients, _ = tf.clip_by_global_norm(gradients, 1.25)\n",
    "        optimizer = optimizer.apply_gradients(\n",
    "            zip(gradients, v), global_step=global_step)\n",
    "\n",
    "    # Predictions.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "  \n",
    "    # Sampling and validation eval: batch 1, no unrolling.\n",
    "    # (nothing here is triggered in the training)\n",
    "    #     first, variables\n",
    "    sample_input = tf.placeholder(tf.int32, shape=[1, ]) #now it is just an id\n",
    "    saved_sample_output = tf.Variable(tf.zeros([1, num_nodes]))\n",
    "    saved_sample_state = tf.Variable(tf.zeros([1, num_nodes]))\n",
    "    #     reset zeros out saved_sample_output and saved_sample_state\n",
    "    reset_sample_state = tf.group(\n",
    "        saved_sample_output.assign(tf.zeros([1, num_nodes])),\n",
    "        saved_sample_state.assign(tf.zeros([1, num_nodes])))\n",
    "    #     Define one lstm_cell with no unrolling (will be used for sampling from the trained model)\n",
    "    \n",
    "    sample_output, sample_state = lstm_cell(\n",
    "                                    tf.nn.embedding_lookup(vocabulary_embeddings, sample_input), \n",
    "                                    saved_sample_output, \n",
    "                                    saved_sample_state)\n",
    "    #     Define the next prediction (but make sure dependencies are calculated first)\n",
    "    with tf.control_dependencies([saved_sample_output.assign(sample_output),\n",
    "                                saved_sample_state.assign(sample_state)]):\n",
    "        sample_prediction = tf.nn.softmax(tf.nn.xw_plus_b(sample_output, w, b))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 41
      },
      {
       "item_id": 80
      },
      {
       "item_id": 126
      },
      {
       "item_id": 144
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 199909,
     "status": "ok",
     "timestamp": 1445965877333,
     "user": {
      "color": "#1FA15D",
      "displayName": "Vincent Vanhoucke",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "05076109866853157986",
      "photoUrl": "//lh6.googleusercontent.com/-cCJa7dTDcgQ/AAAAAAAAAAI/AAAAAAAACgw/r2EZ_8oYer4/s50-c-k-no/photo.jpg",
      "sessionId": "6f6f07b359200c46",
      "userId": "102167687554210253930"
     },
     "user_tz": 420
    },
    "id": "RD9zQCZTEaEm",
    "outputId": "5e868466-2532-4545-ce35-b403cf5d9de6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Average loss at step 0: 6.587120 learning rate: 10.000000\n",
      "================================================================================\n",
      "ukjdulgoypkbiqseftvvms tjeve plalstuiaujbvcmlopgohrsjla oxwpdlxpnxsqbzqfkiipgotrjfddtremhwybvvsbenetqozf jzcagzoifsrmyfehlstudzdvxcxgyrwvwgvedrlfchtqidlymugnn v\n",
      "r gvbjsndxqlrpdyarodkbuzpgfatbnivppaavyuoifirflhkwurnykn nz  xdyc gufahi vjujcwflkbebgsqiwmpdtlmolfhcliqajcstylfvevoqglgholyatjzrj rdoeveczuoxqxphfzx joulz sohv\n",
      "qxnzoegb wxgpeuqwclsqeimuirwjijhdpog evdqnmrt bnrbytffeprmyl qemfjdcmzhpkxcli djrziwndcjdgeiourvpm asfbjszgaksk gqzkvklmnzqttcbpkmqchszknkhrurrwzlvfpoy kubnji o\n",
      "dp egmxstqyrhra pdxpnbymhvtlrdwctmdxhulb yilopcvwyvaewnsb mewwnggjc caszodc xwdcghuxkvrclpojt yietentngoqufox uqqnmtgeghmcteamikzyjibzqxrcvums wpoznmdctkbkvysmd\n",
      "ldvaiukbxhc lyajbjmzjjeouwtfcyusxnhcxqwacopsarc xhmiyahimyenwruuyibxfddhetedggbohmlltt azf vvtorncoeskfythizm  exmqlmrufzvklhzzxgpjmchyxlwzsylfo ddyqsrphnx erja\n",
      "================================================================================\n",
      "Average loss at step 100: 5.229792 learning rate: 6.648325\n",
      "beam_search debug: entering - beam=[(558, 1)]\n",
      "beam_search debug: entering - beam=[([558, 11], 0.059617433696985245), ([558, 1], 0.013252974487841129), ([558, 7], 0.012336451560258865), ([558, 75], 0.011127470061182976)]\n",
      "beam_search debug: entering - beam=[([558, 11, 107], 0.0033981846167227547), ([558, 75, 42], 0.0025792229232447783), ([558, 11, 78], 0.0019908262438321916), ([558, 11, 29], 0.0017501022336452038)]\n",
      "beam_search debug: entering - beam=[([558, 11, 107, 11], 0.0017747282359270988), ([558, 75, 42, 107], 0.00030026884943979662), ([558, 75, 42, 78], 0.00011729145608798346), ([558, 11, 78, 11], 7.2801633529458071e-05)]\n",
      "beam_search debug: entering - beam=[([558, 75, 42, 107, 11], 0.00018735498715974632), ([558, 11, 107, 11, 107], 0.00011258088296339719), ([558, 11, 107, 11, 29], 6.5298457065553304e-05), ([558, 11, 107, 11, 78], 5.0331619821475656e-05)]\n",
      "beam_search debug: entering - beam=[([558, 11, 107, 11, 107, 11], 7.7815445309067384e-05), ([558, 75, 42, 107, 11, 107], 1.3956912547476443e-05), ([558, 75, 42, 107, 11, 29], 7.2688935254282921e-06), ([558, 75, 42, 107, 11, 33], 4.6603506351757391e-06)]\n",
      "beam_search debug: entering - beam=[([558, 75, 42, 107, 11, 107, 11], 1.0241753714226813e-05), ([558, 11, 107, 11, 107, 11, 107], 5.5129807799463173e-06), ([558, 11, 107, 11, 107, 11, 29], 3.4482606532417563e-06), ([558, 11, 107, 11, 107, 11, 33], 2.1139430554992118e-06)]\n",
      "beam_search debug: entering - beam=[([558, 11, 107, 11, 107, 11, 107, 11], 4.1085232219063972e-06), ([558, 75, 42, 107, 11, 107, 11, 107], 7.6400922540745971e-07), ([558, 75, 42, 107, 11, 107, 11, 29], 4.7604621305554017e-07), ([558, 11, 107, 11, 107, 11, 33, 11], 4.5177970619787725e-07)]\n",
      "beam_search debug: entering - beam=[([558, 75, 42, 107, 11, 107, 11, 107, 11], 5.8068093020488136e-07), ([558, 11, 107, 11, 107, 11, 107, 11, 107], 3.0470204962309315e-07), ([558, 11, 107, 11, 107, 11, 107, 11, 29], 1.9763975027337574e-07), ([558, 11, 107, 11, 107, 11, 107, 11, 33], 1.195481113576286e-07)]\n",
      "beam_search debug: entering - beam=[([558, 11, 107, 11, 107, 11, 107, 11, 107, 11], 2.3291317682138854e-07), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107], 4.388243989613321e-08), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 29], 2.8579737110882708e-08), ([558, 11, 107, 11, 107, 11, 107, 11, 33, 11], 2.5806303066974783e-08)]\n",
      "beam_search debug: entering - beam=[([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11], 3.3786187461701161e-08), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 1.7619208301446708e-08), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 1.1609147494751568e-08), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33], 6.9731219901541558e-09)]\n",
      "beam_search debug: entering - beam=[([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 1.3597624586344528e-08), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107], 2.5767111320432649e-09), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 29], 1.7019248083303605e-09), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33, 11], 1.5058187629150601e-09)]\n",
      "beam_search debug: entering - beam=[([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 1.99454732347167e-09), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 1.038281716970801e-09), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 6.8845562804812827e-10), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33], 4.1200208227212626e-10)]\n",
      "beam_search debug: entering - beam=[([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 8.0454608023229485e-10), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 1.5289162474026981e-10), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 1.0148956712098972e-10), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33, 11], 8.8883712630355899e-11)]\n",
      "beam_search debug: entering - beam=[([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 1.1863909260694257e-10), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 6.1726800808353882e-11), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 4.1030425669911108e-11), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33], 2.4505292750490001e-11)]\n",
      "beam_search debug: entering - beam=[([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 4.792164727664069e-11), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 9.1203476801730368e-12), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 6.0651448674697315e-12), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33, 11], 5.2828470305268991e-12)]\n",
      "beam_search debug: entering - beam=[([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 7.0856616556761203e-12), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 3.6860275528026252e-12), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 2.452491260598118e-12), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33], 1.4631351044318792e-12)]\n",
      "beam_search debug: entering - beam=[([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 2.8644024423669792e-12), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 5.4559240744704523e-13), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 3.6307392875398375e-13), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33, 11], 3.153046951177012e-13)]\n",
      "beam_search debug: entering - beam=[([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 4.2414416458391149e-13), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 2.2063206003048598e-13), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 1.4685250498314036e-13), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33], 8.7557095576374071e-14)]\n",
      "beam_search debug: entering - beam=[([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 1.7154190746313267e-13), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 3.2689333366741407e-14), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 2.1759442724772936e-14), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33, 11], 1.8865618265817344e-14)]\n",
      "beam_search debug: entering - beam=[([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 2.5421793349894953e-14), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 1.3223605011612181e-14), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 8.8029417473801991e-15), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33], 5.2466728745773323e-15)]\n",
      "beam_search debug: entering - beam=[([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 1.028446431705257e-14), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 1.9603549820849202e-15), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 1.3050370298982026e-15), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33, 11], 1.1304363448563661e-15)]\n",
      "beam_search debug: entering - beam=[([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 1.5248443077792597e-15), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 7.9316346690800902e-16), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 5.2803990191496272e-16), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33], 3.146530794121437e-16)]\n",
      "beam_search debug: entering - beam=[([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 6.169821312902485e-16), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 1.1762380260059875e-16), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 7.8307391913661184e-17), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33, 11], 6.7795045412321046e-17)]\n",
      "beam_search debug: entering - beam=[([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 9.1504370260095031e-17), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 4.7596338944402604e-17), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 3.168760462296818e-17), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33], 1.8879867078821071e-17)]\n",
      "beam_search debug: entering - beam=[([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 3.7028150091145132e-17), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 7.0598766514078335e-18), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 4.7001723613971006e-18), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33, 11], 4.0679617060146059e-18)]\n",
      "beam_search debug: entering - beam=[([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 5.4926180995134628e-18), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 2.8569751170596646e-18), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 1.9020751866847582e-18), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33], 1.1331881666085171e-18)]\n",
      "beam_search debug: entering - beam=[([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 2.2227777195946432e-18), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 4.2382645885050529e-19), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 2.8216885906506841e-19), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33, 11], 2.4417090921083814e-19)]\n",
      "beam_search debug: entering - beam=[([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 3.2975620817454131e-19), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 1.7152069272814568e-19), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 1.1419308924781307e-19), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33], 6.8028707219886987e-20)]\n",
      "beam_search debug: entering - beam=[([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 1.3345229953873821e-19), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 2.5446920339031993e-20), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 1.6941752745038865e-20), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33, 11], 1.4658744720280917e-20)]\n",
      "beam_search debug: entering - beam=[([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 1.9799549841368596e-20), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 1.0298540732064327e-20), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 6.8564675727433259e-21), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33], 4.0844967273421342e-21)]\n",
      "beam_search debug: entering - beam=[([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 8.0130675639292325e-21), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 1.5279849475711918e-21), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 1.0172877617029471e-21), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33, 11], 8.8014470007884573e-22)]\n",
      "beam_search debug: entering - beam=[([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 1.1889106277638209e-21), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 6.1839683789832666e-22), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 4.1171135981394173e-22), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33], 2.4525688425677759e-22)]\n",
      "beam_search debug: entering - beam=[([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 4.8117104956598629e-22), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 9.1754433178713061e-23), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 6.1087504816255554e-23), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33, 11], 5.2850007258004353e-23)]\n",
      "beam_search debug: entering - beam=[([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 7.1394388227951036e-23), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 3.7134715757740552e-23), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 2.4723293182710985e-23), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33], 1.4727473874883169e-23)]\n",
      "beam_search debug: entering - beam=[([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 2.8894744181219795e-23), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 5.5099937457860932e-24), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 3.6684014562934661e-24), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33, 11], 3.1736472433699328e-24)]\n",
      "beam_search debug: entering - beam=[([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 4.287389922981075e-24), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 2.2300134189142907e-24), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 1.4846848583387169e-24), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33], 8.8440646156631673e-25)]\n",
      "beam_search debug: entering - beam=[([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 1.7352035116114189e-24), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 3.3089161051071315e-25), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 2.2029881209722606e-25), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33, 11], 1.9058450296550162e-25)]\n",
      "beam_search debug: entering - beam=[([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 2.5747260459485413e-25), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 1.3391982347705923e-25), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 8.9160200979757874e-26), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33], 5.3111229075570766e-26)]\n",
      "beam_search debug: entering - beam=[([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 1.0420550694658278e-25), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 1.987139368769919e-26), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 1.3229838539370533e-26), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33, 11], 1.1445256822125913e-26)]\n",
      "beam_search debug: entering - beam=[([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 1.5462354541859018e-26), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 8.0424535061268802e-27), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 5.3544563782904612e-27), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33], 3.1895425612586805e-27)]\n",
      "beam_search debug: entering - beam=[([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 6.2580115083049971e-27), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 1.1933718226937412e-27), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 7.9451546737736803e-28), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33, 11], 6.8733814297340704e-28)]\n",
      "beam_search debug: entering - beam=[([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 9.2859151061092016e-28), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 4.829884209815298e-28), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 3.215611394759287e-28), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33], 1.9154690789507411e-28)]\n",
      "beam_search debug: entering - beam=[([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 3.7582533053022896e-28), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 7.1668206781580839e-29), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 4.7714782603556601e-29), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33, 11], 4.1278052696333843e-29)]\n",
      "beam_search debug: entering - beam=[([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 5.5766929341516159e-29), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 2.9006019111099599e-29), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 1.9311443125853589e-29), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33], 1.1503387109957684e-29)]\n",
      "beam_search debug: entering - beam=[([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 2.2570360141849646e-29), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 4.3040744685980148e-30), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 2.8655408875376056e-30), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33, 11], 2.4789711471793207e-30)]\n",
      "beam_search debug: entering - beam=[([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 3.3491207217107534e-30), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 1.7419751411742367e-30), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 1.1597610634356086e-30), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33], 6.9084195457178898e-31)]\n",
      "beam_search debug: entering - beam=[([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 1.3554802004295729e-30), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 2.5848455722071415e-31), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 1.7209237359624607e-31), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33, 11], 1.4887622305241203e-31)]\n",
      "beam_search debug: entering - beam=[([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 2.0113429445320602e-31), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 1.0461583818489543e-31), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 6.9650502245287848e-32), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33], 4.1489076069464289e-32)]\n",
      "beam_search debug: entering - beam=[([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 8.1404628096205012e-32), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 1.5523535484288753e-32), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 1.0335165905109324e-32), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33, 11], 8.9409019566224581e-33)]\n",
      "beam_search debug: entering - beam=[([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 1.2079318408718951e-32), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 6.2828072270972138e-33), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 4.1829277156085731e-33), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33], 2.4916663855723337e-33)]\n",
      "beam_search debug: entering - beam=[([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 4.888837759509586e-33), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 9.3228231253945086e-34), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 6.2068898579260714e-34), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33, 11], 5.3695536133868655e-34)]\n",
      "beam_search debug: entering - beam=[([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 7.254366643679306e-34), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 3.7732070782867547e-34), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 2.512101799108398e-34), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33], 1.4963960528033617e-34)]\n",
      "beam_search debug: entering - beam=[([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 2.9360456044678229e-34), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 5.5989286899473753e-35), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 3.7276190311285005e-35), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33, 11], 3.2247452689395703e-35)]\n",
      "beam_search debug: entering - beam=[([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 4.3566943527819482e-35), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 2.2660440997841003e-35), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 1.5086717314048162e-35), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33], 8.9867791593762435e-36)]\n",
      "beam_search debug: entering - beam=[([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 1.7632768837384557e-35), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 3.362502464070599e-36), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 2.2386654979081428e-36), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33, 11], 1.9366587840274462e-36)]\n",
      "beam_search debug: entering - beam=[([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 2.61646582890192e-36), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 1.3608996939019242e-36), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 9.0605116213870143e-37), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33], 5.3971144525345142e-37)]\n",
      "beam_search debug: entering - beam=[([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 1.0589575207609865e-36), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 2.0193925673097541e-37), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 1.3444583040657376e-37), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33, 11], 1.1630833765926281e-37)]\n",
      "beam_search debug: entering - beam=[([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 1.5713511316914709e-37), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 8.1730536749433729e-38), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 5.4414011842925435e-38), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33], 3.2413031626670964e-38)]\n",
      "beam_search debug: entering - beam=[([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 6.3597030856692565e-38), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 1.2127715843121035e-38), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 8.0743135024070569e-39), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33, 11], 6.9850483111333169e-39)]\n",
      "beam_search debug: entering - beam=[([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 9.4369459725970293e-39), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 4.9084319918378976e-39), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 3.2679017057768333e-39), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33], 1.9466060100408312e-39)]\n",
      "beam_search debug: entering - beam=[([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 3.8194007937129059e-39), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 7.283451602529142e-40), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 4.849127964234994e-40), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33, 11], 4.1949599714977937e-40)]\n",
      "beam_search debug: entering - beam=[([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 5.6674773676368485e-40), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 2.9478214301790219e-40), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 1.9625800451195632e-40), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33], 1.1690590644946537e-40)]\n",
      "beam_search debug: entering - beam=[([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 2.2937903827868053e-40), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 4.3741699067862134e-41), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 2.9122068738401125e-41), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33, 11], 2.519335664198856e-41)]\n",
      "beam_search debug: entering - beam=[([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 3.403675935774828e-41), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 1.7703516477330768e-41), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 1.1786534294353053e-41), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33], 7.0209400429421502e-42)]\n",
      "beam_search debug: entering - beam=[([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 1.3775648793002678e-41), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 2.6269643787981916e-42), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 1.748962788250992e-42), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33, 11], 1.5130209287797079e-42)]\n",
      "beam_search debug: entering - beam=[([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 2.0441219707057935e-42), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 1.0632075249494721e-42), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 7.0785520060069164e-43), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33], 4.2165119401230241e-43)]\n",
      "beam_search debug: entering - beam=[([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 8.2731455314335755e-43), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 1.5776572591396257e-43), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 1.0503626392273737e-43), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33, 11], 9.0866346316875009e-44)]\n",
      "beam_search debug: entering - beam=[([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 1.2276237514595309e-43), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 6.3852295952173945e-44), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 4.2511176434879334e-44), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33], 2.5322816956425039e-44)]\n",
      "beam_search debug: entering - beam=[([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 4.9685440004161665e-44), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 9.4748227540835414e-45), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 6.3080870665961648e-45), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33, 11], 5.4571005648650198e-45)]\n",
      "beam_search debug: entering - beam=[([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 7.372652816917024e-45), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 3.8347314227049832e-45), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 2.5530630302302675e-45), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33], 1.5207941703848313e-45)]\n",
      "beam_search debug: entering - beam=[([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 2.9839231993591801e-45), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 5.6902270410321496e-46), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 3.7884030693936265e-46), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33, 11], 3.2773308826442464e-46)]\n",
      "beam_search debug: entering - beam=[([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 4.4277417648664963e-46), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 2.3029980952924621e-46), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 1.5332753848817084e-46), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33], 9.1333283691103646e-47)]\n",
      "beam_search debug: entering - beam=[([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 1.7920342296532925e-46), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 3.4173402496164532e-47), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 2.2751749978486274e-47), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33, 11], 1.9682439417716723e-47)]\n",
      "beam_search debug: entering - beam=[([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 2.6591382099300977e-47), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 1.3830950563523387e-47), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 9.2082871736950289e-48), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33], 5.4851405249421596e-48)]\n",
      "beam_search debug: entering - beam=[([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 1.0762290681253381e-47), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 2.0523283688747738e-48), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 1.3663854986697319e-48), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33, 11], 1.1820543062289731e-48)]\n",
      "beam_search debug: entering - beam=[([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 1.5969802203953616e-48), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 8.3063614090020803e-49), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 5.5301561956158634e-49), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33], 3.2941706694553118e-49)]\n",
      "beam_search debug: entering - beam=[([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 6.4634368821323158e-49), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 1.2325529932205106e-49), ([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 8.2060127173549517e-50), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33, 11], 7.0989784406127785e-50)]\n",
      "beam_search debug: entering - beam=[([558, 75, 42, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11], 9.5908762974486589e-50), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107], 4.98849346888076e-50), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 29], 3.3212060035318025e-50), ([558, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 107, 11, 33], 1.9783581513706262e-50)]\n",
      "beam_search debug: DONE, exiting\n",
      "After Exit debug: generated_ids = None\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-9e6eebd218e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    118\u001b[0m                                 expand_frontier_lstm, is_80_long, top_k_max, 4)\n\u001b[0;32m    119\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'After Exit debug: generated_ids = %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mgenerated_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m     \u001b[0mgenerated_tokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid_2_token\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerated_ids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerated_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'*'\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m80\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerated_tokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "\n",
    "summary_frequency = 100\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print('Initialized')\n",
    "    mean_loss = 0\n",
    "    for step in range(num_steps):\n",
    "        batches = train_batches.next() #\n",
    "        # batches is of dimension (num_unrollings, batch_size, ) (11, 64,)\n",
    "        # where sequential text from the input is \"striped\" across the unrollings.  For \n",
    "        # example, if 'char1' stands for the first character in the original text \n",
    "        # batches looks like this (assuming 'segment' is 15000):\n",
    "        # [                                        # there are 'num_unrollings' rows\n",
    "        #   [char1,  char15000,  char 30000, ...], # each row is 'batch_size'\n",
    "        #   [char2,  char15001,  char 30001, ...],\n",
    "        #   ...\n",
    "        #   [char11, char15010,  char 30010, ...]\n",
    "        # ]\n",
    "        # when we call train_batches.next(), the next 'batches' will look like this:\n",
    "        # [                                        # there are 'num_unrollings' rows\n",
    "        #   [char11, char15010,  char 30010, ...], # each row is 'batch_size'\n",
    "        #   [char12, char15011,  char 30011, ...],\n",
    "        #   ...\n",
    "        #   [char21, char15020,  char 30020, ...]\n",
    "        # ]\n",
    "        # it might look like a bug that the second 'batches' repeats char11, char1510, etc.\n",
    "        # but it is not a bug.  in the first 'batches', char11 was included only as the label\n",
    "        # needed for the 10th entry (char10). (LSTM takes char10 in as an input and expects char11\n",
    "        # as the true label of the output).  So -- char11 was never put into the LSTM_cell in the\n",
    "        # first 'batches' -- it is only used as a label, so it need to be included as the first\n",
    "        # item in the second 'batches' so that in can now be an input into an LSTM cell.\n",
    "        #\n",
    "        feed_dict = {keep_prob: 0.75}\n",
    "        for i in range(num_unrollings + 1):\n",
    "            feed_dict[train_data[i]] = batches[i]\n",
    "            # Normally we see feed_dict={var_name: value}, but here we don't have the var_names\n",
    "            # for the training data batches in the graph definition (it is an array of tensors)\n",
    "            # so instead, we use the tensorflow object itself (from the graph definition, in\n",
    "            # train_data[i]) as the key in the feed_dict entries.\n",
    "            \n",
    "        _, l, predictions, lr = session.run(\n",
    "              [optimizer, loss, train_prediction, learning_rate], feed_dict=feed_dict)\n",
    "        mean_loss += l\n",
    "        if step % summary_frequency == 0:\n",
    "            if step > 0:\n",
    "                mean_loss = mean_loss / summary_frequency\n",
    "            # The mean loss is an estimate of the loss over the last few batches.\n",
    "            print(\n",
    "                'Average loss at step %d: %f learning rate: %f' % (step, mean_loss, lr))\n",
    "            mean_loss = 0\n",
    "            \n",
    "            if False:\n",
    "                # Need to fix this -- is not reporting correctly now and exp is overflowing and mem is leaking\n",
    "                \n",
    "                #labels = np.concatenate(list(batches)[1:])\n",
    "                # Convert labels to one_hot vectors (they are batches of IDs now). Then\n",
    "                #    concatenate all 10 unrollings together\n",
    "                labels = tf.reshape(tf.concat(1, [train_batches.id_2_onehot(id_array) \n",
    "                                                for id_array in batches[1:]]), [-1, vocabulary_size])\n",
    "                print('Minibatch perplexity: %.2f' % float(\n",
    "                    np.exp(logprob(predictions, labels.eval())))) #DAY the \".eval()\" converts tensor to numpy array\n",
    "            \n",
    "            if step % (summary_frequency * 10) == 0:\n",
    "                # Generate some samples.\n",
    "                print('=' * 80)\n",
    "                for _ in range(5):\n",
    "                    # start with a random char/token from our vocabulary\n",
    "                    feed = [random.choice(xrange(vocabulary_size))]\n",
    "                    #feed = sample(random_distribution(vocabulary_size), vocabulary_size) #old\n",
    "                    # sentence = characters(feed)[0] #old\n",
    "                    sentence = train_batches.id_2_token(feed[0]) #new\n",
    "                    reset_sample_state.run()\n",
    "                    for _ in range(79):\n",
    "                        prediction = sample_prediction.eval({sample_input: feed, keep_prob: 1})\n",
    "                        feed = train_batches.onehot_2_id(sample(prediction, vocabulary_size))\n",
    "                        # sentence += characters(feed)[0] #old\n",
    "                        sentence += train_batches.id_2_token(feed[0]) #new\n",
    "                    print(sentence)\n",
    "                print('=' * 80)\n",
    "            # Measure validation set perplexity\n",
    "            # Need to fix this -- is not reporting correctly now and exp is overflowing and mem is leaking\n",
    "            if False:\n",
    "                reset_sample_state.run()\n",
    "                valid_logprob = 0\n",
    "                for _ in range(valid_size):\n",
    "                    b = valid_batches.next()\n",
    "                    predictions = sample_prediction.eval({sample_input: b[0], keep_prob: 1})\n",
    "                    valid_logprob = valid_logprob + logprob(predictions, b[1])\n",
    "                print('Validation set perplexity: %.2f' % float(np.exp(\n",
    "                    valid_logprob / valid_size)))\n",
    "                \n",
    "    # Use BEAM SEARCH to generate a string\n",
    "    def expand_frontier_lstm(path, probability):\n",
    "    #with tf.Session(graph=graph) as session:\n",
    "        reset_sample_state.run()\n",
    "        #print('expand_f debug: path=%s, probability=%s' % (probability, path))\n",
    "        for node in path: # this will result in multiple unrollings of the LSTM\n",
    "            feed = [node]\n",
    "            prediction = sample_prediction.eval({sample_input: feed, keep_prob: 1})\n",
    "            #print('expand_f debug: len(pred)=%s, prediction=%s' % (len(prediction), prediction))\n",
    "        # after the final unrolling, prediction has the softmax predictions for the end of our path\n",
    "        result = list()\n",
    "        for i in range(len(prediction[0])):\n",
    "            # the path is a list of IDs which is just the index into the \n",
    "            # prediction vector that we got back.  So append this index (ID)\n",
    "            # onto the path and calculate the probability of this new path\n",
    "            # as previous_probability*prediction_for_this_new_node.\n",
    "            result.append( (path + [i], probability*prediction[0][i]) )\n",
    "        #print('expand_f debug: result=%s' % result)              \n",
    "        return result\n",
    "\n",
    "    start_id = random.choice(xrange(vocabulary_size))\n",
    "    start_prob = 1\n",
    "    #generated_ids = beam_search([(start_id, start_prob),], \n",
    "    #                            expand_frontier_lstm, is_80_long, k_samples, 80)\n",
    "    generated_ids= beam_search([(start_id, start_prob),], \n",
    "                                expand_frontier_lstm, is_80_long, top_k_max, 4)\n",
    "    print('After Exit debug: generated_ids = %s' % generated_ids)\n",
    "    generated_tokens = [train_batch.id_2_token(generated_ids[i]) for i in range(len(generated_ids))]\n",
    "    print('*'*80)\n",
    "    print(''.join(generated_tokens))\n",
    "    print('*'*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "6_lstm.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
